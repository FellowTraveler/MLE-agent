from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.language_models import BaseChatModel
from langchain_core.runnables import chain
from langchain_core.output_parsers import StrOutputParser
from snowflake.connector import connect

from cfg import load_config

def snowflake_config(config):
    snowflake_config = config["snowflake"]
    print(snowflake_config)
    # Create the Snowflake URL
    conn = connect(
        user=snowflake_config["user"],
        password=snowflake_config["password"],
        account=snowflake_config["account"],
        warehouse=snowflake_config["warehouse"],
        database=snowflake_config["database"],
        schema=snowflake_config["schema"]
    )

    return conn


def data_engineering_data_loading():
    # 1. Welcome the user to the MLE-agent
    print("Welcome to the MLE-agent!")

    # 2. Inform them about the current stage
    print("You are currently in the Data Engineering stage.")

    # 3. Ask the user to choose a data store
    print("Please choose a data store by entering the corresponding number:")
    print("1. Snowflake")
    print("2. Databricks")
    print("3. AWS S3")

    # 4. Process user input
    choice = input("Enter your choice (1, 2, or 3): ")

    # 5. Respond according to the user's choice
    data_stores = {
        '1': 'Snowflake',
        '2': 'Databricks',
        '3': 'AWS S3'
    }

    # Validate the user input
    if choice in data_stores:
        print(f"MLE-agent will now help you to load data from {data_stores[choice]}.")
    else:
        print("Invalid choice. Please run the program again and select 1, 2, or 3.")


@chain
def sql_agent(input: str, llm: BaseChatModel):
    """
    Analyze the user's current ML development stage based on their input description.

    Args:
        input (str): The user's input describing their current work.
        llm (BaseChatModel): The language model used for processing the input.

    Returns:
        MLDevelopmentStage: Enum representing the identified ML development stage.
    """
    output_parser = StrOutputParser()
    prompt = PromptTemplate(
        template="""
        You play as a professional data scientist. You are currently in the Data Engineering stage. You will understand 
        users input and generate SQL queries to Snowflake.  Do not add ; at the end of the query.

        The user's input description is: {input}
        The SQL query generated is:
        """,
        input_variables=["input"]
    )

    chain = prompt | llm | output_parser
    return chain.invoke({"input": input})


if __name__ == "__main__":
    # Assuming your configuration file is named 'config.json'

    data_engineering_data_loading()

    config = load_config('../credential.json')
    OPENAI_API_KEY = config["OPENAI_API_KEY"]

    session = snowflake_config(config)

    llm = ChatOpenAI(api_key=OPENAI_API_KEY)

    prompt = "Show me top 5 records from IMDB_TRAIN"

    sql_query = sql_agent.invoke(
        input=prompt,
        llm=llm  # Assuming 'llm' is your instantiated language model
    )

    # we can visualize what sql query is generated by the LLM
    print(sql_query)

    # Create a cursor object
    conn = snowflake_config(config)
    cur = conn.cursor()

    try:
        # Execute a query
        cur.execute(sql_query)

        # Fetch result into DataFrame
        df = cur.fetch_pandas_all()

        # Optionally, you can use this method if the result set is very large and you want to manage memory better:
        # df = pd.concat([chunk for chunk in cur.fetch_pandas_batches()])

    finally:
        # Close the cursor and connection
        cur.close()
        conn.close()

    # Display the first few rows of the DataFrame
    print(df.head())

    df.to_csv('output.csv', index=False)
    print("Data loaded successfully!")
